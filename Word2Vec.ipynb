{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD2VEC MODEL\n",
    "- developed by google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('D:/Sohum/GoogleNews-vectors-negative300.bin',binary = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyed Vectors essentially contain the mapping between words and embeddings. After training, \n",
    "it can be used directly to querry those embeddings in various ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = [\"apple\",\"mango\",\"juice\",\"party\",\"orange\"]\n",
    "input2 = [\"music\",\"dance\",\"sleep\",\"dancer\",\"food\"]\n",
    "input3 = [\"match\",\"player\",\"football\",\"cricket\",\"dancer\"]\n",
    "input4 = [\"india\",\"paris\",\"russia\",\"france\",\"germany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_guava = word_vectors[\"guava\"]\n",
    "v_mango = word_vectors[\"mango\"]\n",
    "v_comp_apple = word_vectors[\"Apple\"]\n",
    "v_samsung = word_vectors[\"Samsung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,) (300,)\n"
     ]
    }
   ],
   "source": [
    "print(v_guava.shape,v_mango.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7192399]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([v_guava],[v_mango])\n",
    "#cosine_similarity([v_comp_apple],[v_samsung])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odd One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_one_out(words):\n",
    "    # Accepts a list of words and returns the odd one out\n",
    "    word_vec = [word_vectors[w] for w in words]\n",
    "    vec_avg = np.mean(word_vec,axis = 0)\n",
    "    lst = []\n",
    "    for z in words:\n",
    "        sim = cosine_similarity([word_vectors[z]],[vec_avg])\n",
    "        lst.append(sim)\n",
    "    odd = np.argmin(lst)\n",
    "    odd_one = words[odd]\n",
    "    return odd_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_one_out(input4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_words(a,b,c,word_vectors):\n",
    "    # Takes three words as input and returns a fourth word which is analogous to the first three\n",
    "    a,b,c = a.lower(),b.lower(),c.lower()\n",
    "    words = word_vectors.vocab.keys()\n",
    "    wa,wb,wc = word_vectors[a],word_vectors[b],word_vectors[c]\n",
    "    max_sim = -100\n",
    "    d = None\n",
    "    for w in words:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        wv = word_vectors[w]\n",
    "        sim1 = cosine_similarity([wb - wa],[wv - wc])\n",
    "        if sim1>max_sim:\n",
    "            max_sim = sim1\n",
    "            d = w\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'princess'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad_2=(\"man\",\"woman\",\"prince\")\n",
    "predict_words(*triad_2,word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the most similar method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive = ['woman','king'],negative = ['man'],topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
